# LLM Gateway Environment Variables

# Server Configuration
HOST=0.0.0.0
PORT=8003
LOG_LEVEL=INFO

# Cache Configuration
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# LangSmith Configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=tu_api_key_de_langsmith_aqui
LANGCHAIN_PROJECT=mcp-agent-http
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Metrics Configuration
METRICS_ENABLED=true

# AWS Bedrock Credentials
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_REGION=us-east-1
BEDROCK_MODEL_ID=us.amazon.nova-pro-v1:0

# OpenAI Credentials
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_DEFAULT_MODEL=gpt-4o-mini
OPENAI_ORG_ID=

# Google Gemini Credentials
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_DEFAULT_MODEL=gemini-pro

# MCP Server URLs (used by agents)
MCP_SERVER_URL=http://toolbox:8000
LLM_GATEWAY_URL=http://llm-gateway:8003

# Logging
LOG_LEVEL=DEBUG
